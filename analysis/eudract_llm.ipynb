{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ed2839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path so the package is importable\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from llm_data_quality_assistant import pipeline\n",
    "from llm_data_quality_assistant.corruptor import RowCorruptionTypes, CellCorruptionTypes\n",
    "from llm_data_quality_assistant.enums import Models\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781d3cd",
   "metadata": {},
   "source": [
    "# 2. Load and Explore EudraCT Data\n",
    "Load the EudraCT dataset and perform exploratory data analysis to understand its structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08101e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns 'placebo' and 'active_comparator' not found in the dataset.\n",
      "eudract_number ->\n",
      "    single_blind,\n",
      "    double_blind,\n",
      "    open,\n",
      "    controlled,\n",
      "    placebo,\n",
      "    active_comparator,\n",
      "    randomised,\n",
      "    crossover,\n",
      "    parallel_group,\n",
      "    arms\n",
      "\n",
      "-- Attributes\n",
      "@open:STRING\n",
      "@single_blind:STRING\n",
      "@double_blind:STRING\n",
      "@randomised:STRING\n",
      "@controlled:STRING\n",
      "@placebo:STRING\n",
      "@active_comparator:STRING\n",
      "@crossover:STRING\n",
      "@parallel_group:STRING\n",
      "@arms:STRING\n",
      "\n",
      "-- Overview of attributes\n",
      "open notin {'Yes', 'No'}\n",
      "single_blind notin {'Yes', 'No'}\n",
      "double_blind notin {'Yes', 'No'}\n",
      "randomised notin {'Yes', 'No'}\n",
      "controlled notin {'Yes', 'No'}\n",
      "placebo notin {'Yes', 'No'}\n",
      "active_comparator notin {'Yes', 'No'}\n",
      "crossover notin {'Yes', 'No'}\n",
      "parallel_group notin {'Yes', 'No'}\n",
      "arms notin {'0', '1', '2+'}\n",
      "\n",
      "-- eudract rules for masking\n",
      "open == 'Yes' & single_blind == 'Yes'\n",
      "open == 'Yes' & double_blind == 'Yes'\n",
      "single_blind == 'Yes' & double_blind == 'Yes'\n",
      "open == 'No' & single_blind == 'No' & double_blind == 'No'\n",
      "\n",
      "-- eudract rules for control\n",
      "controlled == 'No' & placebo == 'Yes'\n",
      "controlled == 'No' & active_comparator == 'Yes'\n",
      "\n",
      "-- crossover and parallel cannot occur simultaneously\n",
      "parallel_group == 'Yes' & crossover == 'Yes'\n",
      "\n",
      "-- arms check\n",
      "arms in {'0', '1'} & placebo == 'Yes'\n",
      "arms in {'0', '1'} & active_comparator == 'Yes'\n",
      "   eudract_number arms controlled crossover double_blind open parallel_group  \\\n",
      "0  2004-000232-91  NaN        Yes        No           No  Yes            Yes   \n",
      "1  2004-000232-91  NaN        NaN        No           No  Yes            NaN   \n",
      "\n",
      "  randomised single_blind  \n",
      "0        Yes           No  \n",
      "1        Yes           No  \n",
      "   eudract_number arms controlled crossover double_blind open parallel_group  \\\n",
      "0  2004-000232-91   2+        Yes        No           No  Yes            Yes   \n",
      "1  2004-000232-91   2+        Yes        No           No  Yes            Yes   \n",
      "\n",
      "  randomised single_blind  \n",
      "0        Yes           No  \n",
      "1        Yes           No  \n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "corrupt_dataset = pd.read_csv(\"../datasets/parker_datasets/eudract/eudract_corrupted_first1000.csv\"\n",
    ")\n",
    "# Drop the columns that contain wrong values accoording to Bronsealer & Acosta (2023)\n",
    "try:\n",
    "    corrupt_dataset.drop(columns=[\"placebo\", \"active_comparator\"], inplace=True)\n",
    "except KeyError:\n",
    "    print(\"Columns 'placebo' and 'active_comparator' not found in the dataset.\")\n",
    "\n",
    "gold_standard = pd.read_csv(\n",
    "    \"../datasets/parker_datasets/eudract/eudract_cleaned_gold_first1000.csv\"\n",
    ")\n",
    "\n",
    "with open(\"../datasets/parker_datasets/eudract/eudract.partialkey\", \"r\") as f:\n",
    "    partial_keys = f.read()\n",
    "\n",
    "with open(\"../datasets/parker_datasets/eudract/eudract.rules\", \"r\") as f:\n",
    "    rules = f.read()\n",
    "\n",
    "print(partial_keys)\n",
    "print(rules)\n",
    "print(corrupt_dataset.head(2))\n",
    "print(gold_standard.head(2))\n",
    "print(type(gold_standard.get(\"eudract_number\").iloc[0]))\n",
    "print(type(corrupt_dataset.get(\"eudract_number\").iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd91d2",
   "metadata": {},
   "source": [
    "# 3. Clean and Merge Data with LLM\n",
    "Use the LLM pipeline to clean and merge the corrupted dataset using the provided rules and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcbc28a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging groups with LLM:   0%|          | 0/524 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging groups with LLM: 100%|██████████| 524/524 [17:47<00:00,  2.04s/it]\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../analysis/merged_lukas/eudract'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     23\u001b[39m merged_df = Pipeline.merge_with_llm(\n\u001b[32m     24\u001b[39m     dataset=corrupt_dataset,\n\u001b[32m     25\u001b[39m     primary_key=primary_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     status_bar=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m time_delta = time.time() - start_time\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../analysis/merged_lukas/eudract/merged_dataset_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m stats_micro = Pipeline.evaluate_micro(\n\u001b[32m     37\u001b[39m     gold_standard=gold_standard,\n\u001b[32m     38\u001b[39m     cleaned_dataset=merged_df,\n\u001b[32m     39\u001b[39m     corrupted_dataset=corrupt_dataset\n\u001b[32m     40\u001b[39m )\n\u001b[32m     41\u001b[39m stats_micro[\u001b[33m\"\u001b[39m\u001b[33mtime_taken\u001b[39m\u001b[33m\"\u001b[39m] = time_delta\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Uni/DataEngineering/bpc_project/venv/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Uni/DataEngineering/bpc_project/venv/lib/python3.13/site-packages/pandas/core/generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Uni/DataEngineering/bpc_project/venv/lib/python3.13/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Uni/DataEngineering/bpc_project/venv/lib/python3.13/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Uni/DataEngineering/bpc_project/venv/lib/python3.13/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Uni/DataEngineering/bpc_project/venv/lib/python3.13/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '../analysis/merged_lukas/eudract'"
     ]
    }
   ],
   "source": [
    "from llm_data_quality_assistant.pipeline import Pipeline\n",
    "from llm_data_quality_assistant.enums import Models\n",
    "import string\n",
    "import json\n",
    "string.punctuation = string.punctuation.replace(\"'\", \"\")  # Remove single quotes from punctuation\n",
    "\n",
    "# Use a primary key for merging\n",
    "primary_key = \"eudract_number\"\n",
    "model = Models.GeminiModels.GEMINI_2_0_FLASH_LITE\n",
    "rows_of_context = 200  # adjust as needed\n",
    "file_name = str(model.value) + f\"_{rows_of_context}_rows_context\"\n",
    "for p in string.punctuation + \" \":\n",
    "    file_name = file_name.replace(p, \"_\")\n",
    "\n",
    "rpm = 30  # or 0 if you want no rate limit\n",
    "\n",
    "additional_prompt = f\"\"\"\n",
    "Here are rows of the dataset to provide context for the cleaning process:\n",
    "{corrupt_dataset.sample(rows_of_context).to_string(index=False)}\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "merged_df = Pipeline.merge_with_llm(\n",
    "    dataset=corrupt_dataset,\n",
    "    primary_key=primary_key,\n",
    "    model_name=model,\n",
    "    rpm=rpm,\n",
    "    additional_prompt=additional_prompt,\n",
    "    verbose=False,\n",
    "    status_bar=True,\n",
    ")\n",
    "time_delta = time.time() - start_time\n",
    "\n",
    "merged_df.to_csv(f\"../analysis/merged_lukas/eudract/merged_dataset_{file_name}.csv\", index=False)\n",
    "\n",
    "stats_micro = Pipeline.evaluate_micro(\n",
    "    gold_standard=gold_standard,\n",
    "    cleaned_dataset=merged_df,\n",
    "    corrupted_dataset=corrupt_dataset\n",
    ")\n",
    "stats_micro[\"time_taken\"] = time_delta\n",
    "print(\"====================================\")\n",
    "print(\"MICRO EVALUATION RESULTS\")\n",
    "print(\"====================================\")\n",
    "pprint(stats_micro)\n",
    "\n",
    "stats_macro = Pipeline.evaluate_macro(\n",
    "    gold_standard=gold_standard,\n",
    "    cleaned_dataset=merged_df,\n",
    "    corrupted_dataset=corrupt_dataset\n",
    ")\n",
    "stats_macro[\"time_taken\"] = time_delta\n",
    "print(\"====================================\")\n",
    "print(\"MACRO EVALUATION RESULTS\")\n",
    "print(\"====================================\")\n",
    "pprint(stats_macro)\n",
    "\n",
    "with open(\n",
    "    f\"../analysis/results/eudract/{file_name}_results_micro.json\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(stats_micro, f, indent=4)\n",
    "\n",
    "with open(f\"../analysis/results/eudract/{file_name}_results_macro.json\", \"w\") as f:\n",
    "    json.dump(stats_macro, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
