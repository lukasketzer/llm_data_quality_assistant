{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5f2dadd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the parent directory to the path so the package is importable\n",
        "sys.path.append(os.path.abspath(\"..\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "344691ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llm_data_quality_assistant import pipeline\n",
        "from llm_data_quality_assistant.corruptor import RowCorruptionTypes, CellCorruptionTypes\n",
        "from llm_data_quality_assistant.enums import Models\n",
        "import pandas as pd\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b281d9cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape shortened corrupt dataset:\n",
            "(206, 22)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(shortened_corrupt_df.shape)\n\u001b[32m     10\u001b[39m p = pipeline.Pipeline(corrupt_dataset)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m merged_df = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclean_single_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrupt_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m shortened_merged_df = merged_df[merged_df[\u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m].isin(gold_standard[\u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m])]\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape merged dataset:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/pipeline.py:63\u001b[39m, in \u001b[36mPipeline.clean_single_dataset\u001b[39m\u001b[34m(self, dataset, model_name)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_single_dataset\u001b[39m(\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     58\u001b[39m     dataset: pd.DataFrame,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     ) = Models.GeminiModels.GEMINI_2_0_FLASH,\n\u001b[32m     62\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     merged_df = \u001b[43mmerge_single_corrupted_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m merged_df\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/llm_integration.py:163\u001b[39m, in \u001b[36mmerge_single_corrupted_dataset\u001b[39m\u001b[34m(model_name, dataset)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame()\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m model = \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Combine all datasets into CSV strings for the prompt\u001b[39;00m\n\u001b[32m    166\u001b[39m csv = dataset.to_csv(index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/llm_models.py:144\u001b[39m, in \u001b[36mget_model\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OpenAIModel(model)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Models.GeminiModels):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeminiModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/llm_models.py:100\u001b[39m, in \u001b[36mGeminiModel.__init__\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(model_name)\n\u001b[32m     99\u001b[39m API_KEY = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mGEMINI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bpc/lib/python3.13/site-packages/google/genai/client.py:219\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[39m\n\u001b[32m    216\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    217\u001b[39m     http_options = HttpOptions(base_url=base_url)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[38;5;28mself\u001b[39m._api_client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_api_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_debug_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mself\u001b[39m._aio = AsyncClient(\u001b[38;5;28mself\u001b[39m._api_client)\n\u001b[32m    230\u001b[39m \u001b[38;5;28mself\u001b[39m._models = Models(\u001b[38;5;28mself\u001b[39m._api_client)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bpc/lib/python3.13/site-packages/google/genai/client.py:265\u001b[39m, in \u001b[36mClient._get_api_client\u001b[39m\u001b[34m(vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m debug_config \u001b[38;5;129;01mand\u001b[39;00m debug_config.client_mode \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    249\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrecord\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    250\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreplay\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    251\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    252\u001b[39m ]:\n\u001b[32m    253\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m ReplayApiClient(\n\u001b[32m    254\u001b[39m       mode=debug_config.client_mode,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    255\u001b[39m       replay_id=debug_config.replay_id,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    262\u001b[39m       http_options=http_options,\n\u001b[32m    263\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBaseApiClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bpc/lib/python3.13/site-packages/google/genai/_api_client.py:437\u001b[39m, in \u001b[36mBaseApiClient.__init__\u001b[39m\u001b[34m(self, vertexai, api_key, credentials, project, location, http_options)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Implicit initialization or missing arguments.\u001b[39;00m\n\u001b[32m    436\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_key:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    438\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMissing key inputs argument! To use the Google AI API,\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    439\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m provide (`api_key`) arguments. To use the Google Cloud API,\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    440\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m provide (`vertexai`, `project` & `location`) arguments.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    441\u001b[39m     )\n\u001b[32m    442\u001b[39m   \u001b[38;5;28mself\u001b[39m._http_options.base_url = \u001b[33m'\u001b[39m\u001b[33mhttps://generativelanguage.googleapis.com/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    443\u001b[39m   \u001b[38;5;28mself\u001b[39m._http_options.api_version = \u001b[33m'\u001b[39m\u001b[33mv1beta\u001b[39m\u001b[33m'\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m: Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments."
          ]
        }
      ],
      "source": [
        "corrupt_dataset = pd.read_csv(\"../datasets/parker_datasets/allergen.csv\")\n",
        "\n",
        "gold_standard = pd.read_csv(\"../datasets/parker_datasets/gold_standard_alergene_pivoted.csv\")\n",
        "\n",
        "shortened_corrupt_df = corrupt_dataset[corrupt_dataset[\"code\"].isin(gold_standard[\"code\"])]\n",
        "\n",
        "print(\"Shape shortened corrupt dataset:\")\n",
        "print(shortened_corrupt_df.shape)\n",
        "\n",
        "p = pipeline.Pipeline(corrupt_dataset)\n",
        "\n",
        "merged_df = p.clean_single_dataset(corrupt_dataset)\n",
        "\n",
        "shortened_merged_df = merged_df[merged_df[\"code\"].isin(gold_standard[\"code\"])]\n",
        "\n",
        "print(\"Shape merged dataset:\")\n",
        "print(merged_df.shape)\n",
        "\n",
        "print(\"Shape shortened merged dataset:\")\n",
        "print(shortened_merged_df.shape)\n",
        "exit(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0784e3dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corruptig datasets....\n",
            "Corruptig done.\n",
            "Start merging...\n",
            "Name,Date of Birth,Address,Country,Email,Phone Number,Job,Company\n",
            "Sean Simpson,1986-11-09,\"831 Smith Mews Suite 382\n",
            "Lauriefurt, KY 43149\",Gambia,garyerickson@example.com,001-392-921-8348,Farm manager,dyjnwcsgeidkyuuxpdrd\n",
            "Sarah Dixon,2000-10-01,\"578 Tanya Forge\n",
            "Richardtown, HI 35984\",Togo,rodriguezlaura@example.org,(220)291-0512,IT sales professional,\"Watson, Wells and Morris\"\n",
            "Michael Mcpherson,1971-04-20,\"7691 Tina Track\n",
            "Port Jameschester, OR 05823\",Mauritius,laura16@example.net,+1-477-732-3033x89296,\"Designer, ceramics/pottery\",Vega-Guerrero\n",
            "Lori Cox,1961-10-12,\"47742 Barker Freeway Suite 354\n",
            "Haleyland, AK 64267\",Syrian Arab Republic,sarahlloyd@example.net,756.277.5148,Heritage manager,\"Chapman, Schmidt and Russell\"\n",
            "Rebecca Campos,1961-08-31,\"970 Torres Ramp Suite 553\n",
            "West Gregoryberg, CO 96854\",Bermuda,eric83@example.net,001-949-432-4365x43327,\"Teacher, English as a foreign language\",\"Martin, Bell and Chung\"\n",
            "Suzanne Vega,1979-11-20,\"31189 Fred Islands\n",
            "South Austin, NC 86828\",Montserrat,shawjason@example.net,366.461.3444,\"Scientist, forensic\",Williams LLC\n",
            "Hannah Bush,1976-02-19,\"1520 Michele Islands\n",
            "West Stacie, MS 94421\",Bulgaria,ldoyle@example.net,001-857-975-5313x2155,Merchant navy officer,Wallace Inc\n",
            "Arthur Hicks,1974-06-26,\"44663 Campbell Streets Suite 193\n",
            "South Robinfurt, ND 89738\",Malta,davidsparks@example.net,951-300-9217,Air cabin crew,Pearson-Bailey\n",
            "Nathaniel White,1998-03-01,\"292 Fuller Alley Suite 411\n",
            "Mooreborough, MS 64417\",Comoros,jonathanhampton@example.net,(308)973-6444x25479,Orthoptist,Peterson-Buck\n",
            "Samantha Ruiz,2005-05-17,\"713 Lewis Centers Apt. 798\n",
            "Christopherton, TX 04855\",Syrian Arab Republic,edward20@example.net,001-892-207-4737x0280,Child psychotherapist,Rodriguez-Hughes\n",
            "merged dataset:\n",
            "                    0              1  \\\n",
            "0                Name  Date of Birth   \n",
            "1        Sean Simpson     1986-11-09   \n",
            "2         Sarah Dixon     2000-10-01   \n",
            "3   Michael Mcpherson     1971-04-20   \n",
            "4            Lori Cox     1961-10-12   \n",
            "5      Rebecca Campos     1961-08-31   \n",
            "6        Suzanne Vega     1979-11-20   \n",
            "7         Hannah Bush     1976-02-19   \n",
            "8        Arthur Hicks     1974-06-26   \n",
            "9     Nathaniel White     1998-03-01   \n",
            "10      Samantha Ruiz     2005-05-17   \n",
            "\n",
            "                                                    2                     3  \\\n",
            "0                                             Address               Country   \n",
            "1      831 Smith Mews Suite 382\\nLauriefurt, KY 43149                Gambia   \n",
            "2              578 Tanya Forge\\nRichardtown, HI 35984                  Togo   \n",
            "3        7691 Tina Track\\nPort Jameschester, OR 05823             Mauritius   \n",
            "4   47742 Barker Freeway Suite 354\\nHaleyland, AK ...  Syrian Arab Republic   \n",
            "5   970 Torres Ramp Suite 553\\nWest Gregoryberg, C...               Bermuda   \n",
            "6          31189 Fred Islands\\nSouth Austin, NC 86828            Montserrat   \n",
            "7         1520 Michele Islands\\nWest Stacie, MS 94421              Bulgaria   \n",
            "8   44663 Campbell Streets Suite 193\\nSouth Robinf...                 Malta   \n",
            "9   292 Fuller Alley Suite 411\\nMooreborough, MS 6...               Comoros   \n",
            "10  713 Lewis Centers Apt. 798\\nChristopherton, TX...  Syrian Arab Republic   \n",
            "\n",
            "                              4                       5  \\\n",
            "0                         Email            Phone Number   \n",
            "1      garyerickson@example.com        001-392-921-8348   \n",
            "2    rodriguezlaura@example.org           (220)291-0512   \n",
            "3           laura16@example.net   +1-477-732-3033x89296   \n",
            "4        sarahlloyd@example.net            756.277.5148   \n",
            "5            eric83@example.net  001-949-432-4365x43327   \n",
            "6         shawjason@example.net            366.461.3444   \n",
            "7            ldoyle@example.net   001-857-975-5313x2155   \n",
            "8       davidsparks@example.net            951-300-9217   \n",
            "9   jonathanhampton@example.net     (308)973-6444x25479   \n",
            "10         edward20@example.net   001-892-207-4737x0280   \n",
            "\n",
            "                                         6                             7  \n",
            "0                                      Job                       Company  \n",
            "1                             Farm manager          dyjnwcsgeidkyuuxpdrd  \n",
            "2                    IT sales professional      Watson, Wells and Morris  \n",
            "3               Designer, ceramics/pottery                 Vega-Guerrero  \n",
            "4                         Heritage manager  Chapman, Schmidt and Russell  \n",
            "5   Teacher, English as a foreign language        Martin, Bell and Chung  \n",
            "6                      Scientist, forensic                  Williams LLC  \n",
            "7                    Merchant navy officer                   Wallace Inc  \n",
            "8                           Air cabin crew                Pearson-Bailey  \n",
            "9                               Orthoptist                 Peterson-Buck  \n",
            "10                   Child psychotherapist              Rodriguez-Hughes  \n",
            "(11, 8)\n",
            "Merging done.\n"
          ]
        },
        {
          "ename": "ValueError",
<<<<<<< Updated upstream
          "evalue": "Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.",
=======
          "evalue": "Datasets must have the same shape for evaluation.",
>>>>>>> Stashed changes
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
<<<<<<< Updated upstream
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Example: merge the corrupted datasets using LLM\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStart merging...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m merged_df = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrupted_datasets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMerging done.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m stats = p.evaluate_micro(merged_df, corrupted_coords)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/pipeline.py:51\u001b[39m, in \u001b[36mPipeline.merge_with_llm\u001b[39m\u001b[34m(self, datasets, model_name)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge_with_llm\u001b[39m(\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     46\u001b[39m     datasets: \u001b[38;5;28mlist\u001b[39m[pd.DataFrame],\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     ) = Models.GeminiModels.GEMINI_2_0_FLASH,\n\u001b[32m     50\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     merged_df = \u001b[43mmerge_dataset_in_chunks_with_llm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m merged_df\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/llm_integration.py:148\u001b[39m, in \u001b[36mmerge_dataset_in_chunks_with_llm\u001b[39m\u001b[34m(model_name, datasets, chunk_size)\u001b[39m\n\u001b[32m    146\u001b[39m     end = \u001b[38;5;28mmin\u001b[39m(start + chunk_size, num_rows)\n\u001b[32m    147\u001b[39m     chunk_dfs = [df.iloc[start:end] \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     merged_chunk = \u001b[43mmerge_datasets_group_by_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_dfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m     merged_chunks.append(merged_chunk)\n\u001b[32m    150\u001b[39m merged_df = pd.concat(merged_chunks, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/llm_integration.py:13\u001b[39m, in \u001b[36mmerge_datasets_group_by_rows\u001b[39m\u001b[34m(model_name, datasets)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge_datasets_group_by_rows\u001b[39m(\n\u001b[32m      8\u001b[39m     model_name, datasets: \u001b[38;5;28mlist\u001b[39m[pd.DataFrame]\n\u001b[32m      9\u001b[39m ) -> pd.DataFrame:\n\u001b[32m     10\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    Merges multiple datasets about the same thing using an LLM to resolve errors and output the most likely true values.\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     model = \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     n_rows, n_cols = datasets[\u001b[32m0\u001b[39m].shape\n\u001b[32m     15\u001b[39m     cols = datasets[\u001b[32m0\u001b[39m].columns.tolist()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/llm_models.py:144\u001b[39m, in \u001b[36mget_model\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OpenAIModel(model)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Models.GeminiModels):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeminiModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Uni/llm_data_quality_assistant/llm_data_quality_assistant/llm_models.py:100\u001b[39m, in \u001b[36mGeminiModel.__init__\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(model_name)\n\u001b[32m     99\u001b[39m API_KEY = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mGEMINI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bpc/lib/python3.13/site-packages/google/genai/client.py:219\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[39m\n\u001b[32m    216\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    217\u001b[39m     http_options = HttpOptions(base_url=base_url)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[38;5;28mself\u001b[39m._api_client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_api_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_debug_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mself\u001b[39m._aio = AsyncClient(\u001b[38;5;28mself\u001b[39m._api_client)\n\u001b[32m    230\u001b[39m \u001b[38;5;28mself\u001b[39m._models = Models(\u001b[38;5;28mself\u001b[39m._api_client)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bpc/lib/python3.13/site-packages/google/genai/client.py:265\u001b[39m, in \u001b[36mClient._get_api_client\u001b[39m\u001b[34m(vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m debug_config \u001b[38;5;129;01mand\u001b[39;00m debug_config.client_mode \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    249\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrecord\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    250\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreplay\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    251\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    252\u001b[39m ]:\n\u001b[32m    253\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m ReplayApiClient(\n\u001b[32m    254\u001b[39m       mode=debug_config.client_mode,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    255\u001b[39m       replay_id=debug_config.replay_id,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    262\u001b[39m       http_options=http_options,\n\u001b[32m    263\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBaseApiClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bpc/lib/python3.13/site-packages/google/genai/_api_client.py:437\u001b[39m, in \u001b[36mBaseApiClient.__init__\u001b[39m\u001b[34m(self, vertexai, api_key, credentials, project, location, http_options)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Implicit initialization or missing arguments.\u001b[39;00m\n\u001b[32m    436\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_key:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    438\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMissing key inputs argument! To use the Google AI API,\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    439\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m provide (`api_key`) arguments. To use the Google Cloud API,\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    440\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m provide (`vertexai`, `project` & `location`) arguments.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    441\u001b[39m     )\n\u001b[32m    442\u001b[39m   \u001b[38;5;28mself\u001b[39m._http_options.base_url = \u001b[33m'\u001b[39m\u001b[33mhttps://generativelanguage.googleapis.com/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    443\u001b[39m   \u001b[38;5;28mself\u001b[39m._http_options.api_version = \u001b[33m'\u001b[39m\u001b[33mv1beta\u001b[39m\u001b[33m'\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m: Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments."
=======
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m merged_df = p.merge_with_llm(corrupted_datasets)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMerging done.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m stats = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_micro\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrupted_coords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMicro evaluation stats:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m pprint(stats)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Uni/DataEngineering/bpc_project/llm_data_quality_assistant/pipeline.py:70\u001b[39m, in \u001b[36mPipeline.evaluate_micro\u001b[39m\u001b[34m(self, generated_dataset, corrupted_coords)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_micro\u001b[39m(\u001b[38;5;28mself\u001b[39m, generated_dataset, corrupted_coords):\n\u001b[32m     69\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Evaluate a generated dataset using micro metrics.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate_dataset_micro\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrupted_coords\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Uni/DataEngineering/bpc_project/llm_data_quality_assistant/evaluation.py:110\u001b[39m, in \u001b[36mevaluate_dataset_micro\u001b[39m\u001b[34m(gold_standard, generated_dataset, corrupted_coords)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03mEvaluate the generated dataset against a gold standard dataset.\u001b[39;00m\n\u001b[32m    101\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m    dict: A dictionary containing evaluation metrics.\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gold_standard.shape != generated_dataset.shape:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDatasets must have the same shape for evaluation.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m n_rows, n_cols = gold_standard.shape\n\u001b[32m    112\u001b[39m corrupted_coords_flattened = np.array(\n\u001b[32m    113\u001b[39m     [coord \u001b[38;5;28;01mfor\u001b[39;00m coords \u001b[38;5;129;01min\u001b[39;00m corrupted_coords \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m coords]\n\u001b[32m    114\u001b[39m )\n",
            "\u001b[31mValueError\u001b[39m: Datasets must have the same shape for evaluation."
>>>>>>> Stashed changes
          ]
        }
      ],
      "source": [
        "gold_standard = pd.read_csv(\n",
        "    \"../datasets/simple_dataset/simple_dataset.csv\"\n",
        ").head(\n",
        "    20\n",
        ")  # Load a sample of the dataset\n",
        "p = pipeline.Pipeline(gold_standard)\n",
        "\n",
        "row_corruption_types = [RowCorruptionTypes.SHUFFLE_COLUMNS]\n",
        "cell_corruption_types = [CellCorruptionTypes.OUTLIER, CellCorruptionTypes.NULL]\n",
        "print(\"Corruptig datasets....\")\n",
        "corrupted_datasets, corrupted_coords = p.generate_corrupted_datasets(\n",
        "    row_corruption_type=row_corruption_types,\n",
        "    cell_corruption_type=cell_corruption_types,\n",
        "    severity=0.5,\n",
        "    output_size=5,\n",
        ")\n",
        "print(\"Corruptig done.\")\n",
        "\n",
        "# Example: merge the corrupted datasets using LLM\n",
        "print(\"Start merging...\")\n",
        "merged_df = p.merge_with_llm(corrupted_datasets)\n",
        "print(\"Merging done.\")\n",
        "\n",
        "stats = p.evaluate_micro(merged_df, corrupted_coords)\n",
        "print(\"Micro evaluation stats:\")\n",
        "pprint(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5819ff",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c6c08b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0b5ab129",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bpc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
