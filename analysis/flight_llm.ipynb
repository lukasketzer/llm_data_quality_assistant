{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b16bf85",
   "metadata": {},
   "source": [
    "# 1. Import Required Libraries\n",
    "Import libraries such as pandas, numpy, and the LLM pipeline for data handling and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31c074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path so the package is importable\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from llm_data_quality_assistant.enums import Models\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import jupyter_helper_functions\n",
    "import string\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ec585",
   "metadata": {},
   "source": [
    "# 2. Load and Explore Flight Data\n",
    "Load the flight dataset and perform exploratory data analysis to understand its structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eeb490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_collected, flight_number ->\n",
      "    scheduled_departure,\n",
      "    actual_departure,\n",
      "    scheduled_arrival,\n",
      "    actual_arrival\n",
      "\n",
      "-- Attributes\n",
      "@scheduled_departure:datetime_in_minutes\n",
      "@scheduled_arrival:datetime_in_minutes\n",
      "@actual_departure:datetime_in_minutes\n",
      "@actual_arrival:datetime_in_minutes\n",
      "\n",
      "-- Sigma rules\n",
      "scheduled_departure >= scheduled_arrival\n",
      "actual_departure >= actual_arrival\n",
      "actual_departure >= scheduled_departure\n",
      "actual_departure <= scheduled_departure\n",
      "\n",
      "                   composed_key  actual_arrival  actual_departure  \\\n",
      "0  2011-12-01 - AA-1007-MIA-PHX          3055.0            2756.0   \n",
      "1  2011-12-01 - AA-1007-MIA-PHX          3055.0            2756.0   \n",
      "\n",
      "   scheduled_arrival  scheduled_departure  \n",
      "0             3065.0               2755.0  \n",
      "1             3065.0               2755.0  \n",
      "                   composed_key  actual_arrival  actual_departure  \\\n",
      "0  2011-12-01 - AA-1007-MIA-PHX          3055.0            2768.0   \n",
      "1  2011-12-01 - AA-1007-MIA-PHX          3055.0            2768.0   \n",
      "\n",
      "   scheduled_arrival  scheduled_departure  \n",
      "0             3065.0               2755.0  \n",
      "1             3065.0               2755.0  \n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "corrupt_dataset = jupyter_helper_functions.load_dataset(\n",
    "    \"../datasets/parker_datasets/flight/flightcleaned_corrupted_first1000.csv\"\n",
    ")\n",
    "gold_standard = jupyter_helper_functions.load_dataset(\n",
    "    \"../datasets/parker_datasets/flight/flight_cleaned_gold_first1000.csv\"\n",
    ")\n",
    "\n",
    "partial_keys = jupyter_helper_functions.load_text_file(\"../datasets/parker_datasets/flight/flight.partialkey\")\n",
    "rules = jupyter_helper_functions.load_text_file(\"../datasets/parker_datasets/flight/flight.rules\")\n",
    "\n",
    "# print(partial_keys)\n",
    "# print(rules)\n",
    "# print(corrupt_dataset.head(2))\n",
    "# print(gold_standard.head(2))\n",
    "# print(type(gold_standard.get(\"composed_key\").iloc[0]))\n",
    "# print(type(corrupt_dataset.get(\"composed_key\").iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b548f131",
   "metadata": {},
   "source": [
    "# 3. Clean and Merge Data with LLM\n",
    "Use the LLM pipeline to clean and merge the corrupted dataset using the provided rules and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb1128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging groups with LLM: 100%|██████████| 1000/1000 [33:32<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       composed_key  actual_arrival  actual_departure  \\\n",
      "0      2011-12-01 - AA-1007-MIA-PHX          3055.0            2769.0   \n",
      "1      2011-12-01 - AA-1007-MIA-PHX          3055.0            2769.0   \n",
      "2      2011-12-01 - AA-1007-MIA-PHX          3055.0            2769.0   \n",
      "3      2011-12-01 - AA-1007-MIA-PHX          3055.0            2769.0   \n",
      "4      2011-12-01 - AA-1007-MIA-PHX          3055.0            2769.0   \n",
      "...                             ...             ...               ...   \n",
      "24601   2012-01-03 - UA-938-DEN-ORD         50471.0           50359.0   \n",
      "24602   2012-01-03 - UA-938-DEN-ORD         50471.0           50359.0   \n",
      "24603   2012-01-03 - UA-938-DEN-ORD         50471.0           50359.0   \n",
      "24604   2012-01-03 - UA-938-DEN-ORD         50471.0           50359.0   \n",
      "24605   2012-01-03 - UA-938-DEN-ORD         50471.0           50359.0   \n",
      "\n",
      "       scheduled_arrival  scheduled_departure  \n",
      "0                 3065.0               2755.0  \n",
      "1                 3065.0               2755.0  \n",
      "2                 3065.0               2755.0  \n",
      "3                 3065.0               2755.0  \n",
      "4                 3065.0               2755.0  \n",
      "...                  ...                  ...  \n",
      "24601            50498.0              50344.0  \n",
      "24602            50498.0              50344.0  \n",
      "24603            50498.0              50344.0  \n",
      "24604            50498.0              50344.0  \n",
      "24605            50498.0              50344.0  \n",
      "\n",
      "[24606 rows x 5 columns]\n",
      "                       composed_key  actual_arrival  actual_departure  \\\n",
      "0      2011-12-01 - AA-1007-MIA-PHX          3055.0            2768.0   \n",
      "1      2011-12-01 - AA-1007-MIA-PHX          3055.0            2768.0   \n",
      "2      2011-12-01 - AA-1007-MIA-PHX          3055.0            2768.0   \n",
      "3      2011-12-01 - AA-1007-MIA-PHX          3055.0            2768.0   \n",
      "4      2011-12-01 - AA-1007-MIA-PHX          3055.0            2768.0   \n",
      "...                             ...             ...               ...   \n",
      "24601   2012-01-03 - UA-938-DEN-ORD         50471.0           50344.0   \n",
      "24602   2012-01-03 - UA-938-DEN-ORD         50471.0           50344.0   \n",
      "24603   2012-01-03 - UA-938-DEN-ORD         50471.0           50344.0   \n",
      "24604   2012-01-03 - UA-938-DEN-ORD         50471.0           50344.0   \n",
      "24605   2012-01-03 - UA-938-DEN-ORD         50471.0           50344.0   \n",
      "\n",
      "       scheduled_arrival  scheduled_departure  \n",
      "0                 3065.0               2755.0  \n",
      "1                 3065.0               2755.0  \n",
      "2                 3065.0               2755.0  \n",
      "3                 3065.0               2755.0  \n",
      "4                 3065.0               2755.0  \n",
      "...                  ...                  ...  \n",
      "24601            50498.0              50344.0  \n",
      "24602            50498.0              50344.0  \n",
      "24603            50498.0              50344.0  \n",
      "24604            50498.0              50344.0  \n",
      "24605            50498.0              50344.0  \n",
      "\n",
      "[24606 rows x 5 columns]\n",
      "                       composed_key  actual_arrival  actual_departure  \\\n",
      "0      2011-12-01 - AA-1007-MIA-PHX          3055.0            2756.0   \n",
      "1      2011-12-01 - AA-1007-MIA-PHX          3055.0            2756.0   \n",
      "2      2011-12-01 - AA-1007-MIA-PHX          3043.0            2769.0   \n",
      "3      2011-12-01 - AA-1007-MIA-PHX          3043.0            2768.0   \n",
      "4      2011-12-01 - AA-1007-MIA-PHX          3053.0            2769.0   \n",
      "...                             ...             ...               ...   \n",
      "24601   2012-01-03 - UA-938-DEN-ORD         50471.0           50359.0   \n",
      "24602   2012-01-03 - UA-938-DEN-ORD             NaN           50359.0   \n",
      "24603   2012-01-03 - UA-938-DEN-ORD         50461.0           50359.0   \n",
      "24604   2012-01-03 - UA-938-DEN-ORD         50471.0           50344.0   \n",
      "24605   2012-01-03 - UA-938-DEN-ORD         50461.0           50357.0   \n",
      "\n",
      "       scheduled_arrival  scheduled_departure  \n",
      "0                 3065.0               2755.0  \n",
      "1                 3065.0               2755.0  \n",
      "2                    NaN                  NaN  \n",
      "3                 3038.0               2755.0  \n",
      "4                    NaN                  NaN  \n",
      "...                  ...                  ...  \n",
      "24601                NaN                  NaN  \n",
      "24602                NaN                  NaN  \n",
      "24603                NaN                  NaN  \n",
      "24604            50498.0              50344.0  \n",
      "24605                NaN                  NaN  \n",
      "\n",
      "[24606 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from llm_data_quality_assistant.pipeline import Pipeline\n",
    "from llm_data_quality_assistant.enums import Models\n",
    "import jupyter_helper_functions\n",
    "import string\n",
    "import time\n",
    "string.punctuation = string.punctuation.replace(\"'\", \"\")  # Remove single quotes from punctuation\n",
    "\n",
    "# Use a primary key for merging\n",
    "primary_key = \"composed_key\"\n",
    "model = Models.GeminiModels.GEMINI_2_0_FLASH_LITE\n",
    "rows_of_context = 50\n",
    "\n",
    "extra = \"simple approach\"\n",
    "file_name = jupyter_helper_functions.sanitize_filename(f\"{model.value}_{rows_of_context}_rows_context_{extra}\")   \n",
    "\n",
    "rpm = 30\n",
    "additional_prompt = f\"\"\"\n",
    "Here are rows of the dataset to provide context for the cleaning process:\n",
    "{corrupt_dataset.sample(rows_of_context).to_string(index=False)}\n",
    "\"\"\"\n",
    "\n",
    "# Merge/clean with LLM\n",
    "merged_df, time_taken = jupyter_helper_functions.merge_with_llm_timed(\n",
    "    dataset = corrupt_dataset,\n",
    "    primary_key = primary_key,\n",
    "    model = model,\n",
    "    rpm = rpm,\n",
    "    additional_prompt = additional_prompt\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4b317",
   "metadata": {},
   "source": [
    "# 4. Evaluate the Results\n",
    "Evaluate the cleaned dataset using micro and macro evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da501181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "MICRO EVALUATION RESULTS\n",
      "====================================\n",
      "{'accuracy': 0.7491018450784361,\n",
      " 'column_names': ['composed_key',\n",
      "                  'actual_arrival',\n",
      "                  'actual_departure',\n",
      "                  'scheduled_arrival',\n",
      "                  'scheduled_departure'],\n",
      " 'f1_score': 0.6398553260996384,\n",
      " 'false_negative': 20042,\n",
      " 'false_negative_rate': 0.4222657649116154,\n",
      " 'false_positive': 10826,\n",
      " 'false_positive_rate': 0.14326359389680682,\n",
      " 'num_columns': 5,\n",
      " 'num_rows': 24606,\n",
      " 'precision': 0.7169451198786833,\n",
      " 'recall': 0.5777342350883846,\n",
      " 'true_negative': 64741,\n",
      " 'true_positive': 27421}\n",
      "====================================\n",
      "MACRO EVALUATION RESULTS\n",
      "====================================\n",
      "{'column_names': ['composed_key',\n",
      "                  'actual_arrival',\n",
      "                  'actual_departure',\n",
      "                  'scheduled_arrival',\n",
      "                  'scheduled_departure'],\n",
      " 'num_columns': 5,\n",
      " 'num_rows': 24606,\n",
      " 'stats': [{'accuracy': 1.0,\n",
      "            'column_name': 'composed_key',\n",
      "            'f1_score': 0.0,\n",
      "            'false_negative': 0,\n",
      "            'false_negative_rate': 0.0,\n",
      "            'false_positive': 0,\n",
      "            'false_positive_rate': 0.0,\n",
      "            'num_entries': 24606,\n",
      "            'precision': 0.0,\n",
      "            'recall': 0.0,\n",
      "            'true_negative': 24606,\n",
      "            'true_positive': 0},\n",
      "           {'accuracy': 0.7517678614971958,\n",
      "            'column_name': 'actual_arrival',\n",
      "            'f1_score': 0.7420825943754751,\n",
      "            'false_negative': 3806,\n",
      "            'false_negative_rate': 0.30223139839593427,\n",
      "            'false_positive': 2302,\n",
      "            'false_positive_rate': 0.1916257387829851,\n",
      "            'num_entries': 24606,\n",
      "            'precision': 0.792406889710524,\n",
      "            'recall': 0.6977686016040657,\n",
      "            'true_negative': 9711,\n",
      "            'true_positive': 8787},\n",
      "           {'accuracy': 0.0927822482321385,\n",
      "            'column_name': 'actual_departure',\n",
      "            'f1_score': 0.09097202427006557,\n",
      "            'false_negative': 14868,\n",
      "            'false_negative_rate': 0.9301219893650298,\n",
      "            'false_positive': 7455,\n",
      "            'false_positive_rate': 0.8647488690407146,\n",
      "            'num_entries': 24606,\n",
      "            'precision': 0.13030797946803546,\n",
      "            'recall': 0.06987801063497029,\n",
      "            'true_negative': 1166,\n",
      "            'true_positive': 1117},\n",
      "           {'accuracy': 0.9058359749654555,\n",
      "            'column_name': 'scheduled_arrival',\n",
      "            'f1_score': 0.8894086201135983,\n",
      "            'false_negative': 1275,\n",
      "            'false_negative_rate': 0.1203738670694864,\n",
      "            'false_positive': 1042,\n",
      "            'false_positive_rate': 0.07435421721136007,\n",
      "            'num_entries': 24606,\n",
      "            'precision': 0.8994111400714355,\n",
      "            'recall': 0.8796261329305136,\n",
      "            'true_negative': 12972,\n",
      "            'true_positive': 9317},\n",
      "           {'accuracy': 0.9951231406973908,\n",
      "            'column_name': 'scheduled_departure',\n",
      "            'f1_score': 0.9927360774818402,\n",
      "            'false_negative': 93,\n",
      "            'false_negative_rate': 0.011214277101169661,\n",
      "            'false_positive': 27,\n",
      "            'false_positive_rate': 0.0016551216820940354,\n",
      "            'num_entries': 24606,\n",
      "            'precision': 0.9967181232527045,\n",
      "            'recall': 0.9887857228988304,\n",
      "            'true_negative': 16286,\n",
      "            'true_positive': 8200}]}\n"
     ]
    }
   ],
   "source": [
    "# (Evaluation is now handled by standardize_and_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "# Save merged dataset\n",
    "jupyter_helper_functions.save_dataframe_csv(merged_df, f\"../analysis/repairs/flight/merged_dataset_{file_name}.csv\")\n",
    "\n",
    "# Evaluate results\n",
    "jupyter_helper_functions.standardize_and_evaluate(\n",
    "    gold_standard=gold_standard,\n",
    "    merged_df=merged_df,\n",
    "    corrupt_dataset=corrupt_dataset,\n",
    "    primary_key=primary_key,\n",
    "    time_delta=time_taken,\n",
    "    results_dir=f\"../analysis/results/flight/\",\n",
    "    file_name=file_name,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
