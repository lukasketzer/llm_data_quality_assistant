{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0da71cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path so the package is importable\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from llm_data_quality_assistant.corruptor import RowCorruptionTypes, CellCorruptionTypes\n",
    "from llm_data_quality_assistant.enums import Models\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e2ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_dataset = pd.read_csv(\n",
    "    \"../datasets/parker_datasets/allergen/allergen_corrupted_first1000.csv\"\n",
    ")\n",
    "\n",
    "gold_standard = pd.read_csv(\"../datasets/parker_datasets/allergen/allergen_cleaned_gold_first1000.csv\")\n",
    "\n",
    "# Reorder columns of corrupt_dataset to match gold_standard\n",
    "corrupt_dataset = corrupt_dataset[gold_standard.columns]\n",
    "\n",
    "with open(\"../datasets/parker_datasets/allergen/allergen.partialkey\", \"r\") as f:\n",
    "    partial_keys = f.read()\n",
    "\n",
    "with open(\"../datasets/parker_datasets/allergen/allergen.rules\", \"r\") as f:\n",
    "    rules = f.read()\n",
    "\n",
    "\n",
    "# print(partial_keys)\n",
    "# print(rules)\n",
    "# print(corrupt_dataset.head(2))\n",
    "# print(gold_standard.head(2))\n",
    "# print(type(gold_standard.get(\"code\").iloc[0]))\n",
    "# print(type(corrupt_dataset.get(\"code\").iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cb1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortened_corrupt_df = corrupt_dataset[corrupt_dataset[\"code\"].isin(gold_standard[\"code\"])]\n",
    "# shortened_corrupt_df = shortened_corrupt_df.sort_values(by=\"code\").reset_index(drop=True)\n",
    "\n",
    "# print(\"Shape shortened corrupt dataset:\")\n",
    "# print(shortened_corrupt_df.shape)\n",
    "\n",
    "# print(shortened_corrupt_df)\n",
    "\n",
    "# shortened_gold_standard = gold_standard[gold_standard[\"code\"].isin(shortened_corrupt_df[\"code\"])]\n",
    "# shortened_gold_standard = shortened_gold_standard.sort_values(by=\"code\").reset_index(drop=True)\n",
    "\n",
    "# print(\"Shape shortened gold standard dataset:\")\n",
    "# print(shortened_gold_standard.shape)\n",
    "\n",
    "# print(shortened_gold_standard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "845980fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging groups with LLM: 100%|██████████| 103/103 [03:39<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Clean and evaluate using the new Pipeline API\n",
    "from llm_data_quality_assistant.pipeline import Pipeline\n",
    "from llm_data_quality_assistant.enums import Models\n",
    "import jupyter_helper_functions\n",
    "import string\n",
    "string.punctuation = string.punctuation.replace(\"'\", \"\")  # Remove single quotes from punctuation\n",
    "\n",
    "# Use a primary key for merging\n",
    "primary_key = \"code\"\n",
    "model = Models.GeminiModels.GEMINI_2_0_FLASH_LITE\n",
    "rows_of_context = 50\n",
    "\n",
    "\n",
    "extra = \"simple approach\"\n",
    "\n",
    "file_name = jupyter_helper_functions.sanitize_filename(f\"{model.value}_{rows_of_context}_rows_context_{extra}\")   \n",
    "\n",
    "rpm = 30\n",
    "additional_prompt = f\"\"\"\n",
    "Here are rows of the dataset to provide context for the cleaning process:\n",
    "{corrupt_dataset.sample(rows_of_context).to_string(index=False)}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Merge/clean with LLM\n",
    "merged_df, time_taken = jupyter_helper_functions.merge_with_llm_timed(\n",
    "    dataset = corrupt_dataset,\n",
    "    primary_key = primary_key,\n",
    "    model = model,\n",
    "    rpm = rpm,\n",
    "    additional_prompt = additional_prompt\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2409a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter_helper_functions.save_dataframe_csv(merged_df, f\"../analysis/repairs/allergen/merged_dataset_{file_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d4bac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Standardized micro evaluation: {'num_rows': 206, 'num_columns': 22, \"\n",
      " \"'column_names': ['code', 'nuts', 'almondnuts', 'brazil_nuts', \"\n",
      " \"'macadamia_nuts', 'hazelnut', 'pistachio', 'walnut', 'cashew', 'celery', \"\n",
      " \"'crustaceans', 'eggs', 'fish', 'gluten', 'lupin', 'milk', 'molluscs', \"\n",
      " \"'mustard', 'peanut', 'sesame', 'soy', 'sulfite'], 'true_positive': 105, \"\n",
      " \"'false_positive': 49, 'false_negative': 253, 'true_negative': 4125, \"\n",
      " \"'precision': 0.6818181818181818, 'recall': 0.29329608938547486, 'f1_score': \"\n",
      " \"0.41015624999999994, 'accuracy': 0.9333627537511032, 'false_positive_rate': \"\n",
      " \"0.011739338763775755, 'false_negative_rate': 0.7067039106145251, \"\n",
      " \"'time_taken': 219.03006076812744}\")\n",
      "(\"Standardized macro evaluation: {'num_rows': 206, 'num_columns': 22, \"\n",
      " \"'column_names': ['code', 'nuts', 'almondnuts', 'brazil_nuts', \"\n",
      " \"'macadamia_nuts', 'hazelnut', 'pistachio', 'walnut', 'cashew', 'celery', \"\n",
      " \"'crustaceans', 'eggs', 'fish', 'gluten', 'lupin', 'milk', 'molluscs', \"\n",
      " \"'mustard', 'peanut', 'sesame', 'soy', 'sulfite'], 'stats': [{'num_entries': \"\n",
      " \"206, 'column_name': 'code', 'true_positive': 0, 'false_positive': 0, \"\n",
      " \"'false_negative': 0, 'true_negative': 206, 'precision': 0.0, 'recall': 0.0, \"\n",
      " \"'f1_score': 0.0, 'accuracy': 1.0, 'false_positive_rate': 0.0, \"\n",
      " \"'false_negative_rate': 0.0}, {'num_entries': 206, 'column_name': 'nuts', \"\n",
      " \"'true_positive': 20, 'false_positive': 5, 'false_negative': 21, \"\n",
      " \"'true_negative': 160, 'precision': 0.8, 'recall': 0.4878048780487805, \"\n",
      " \"'f1_score': 0.6060606060606061, 'accuracy': 0.8737864077669902, \"\n",
      " \"'false_positive_rate': 0.030303030303030304, 'false_negative_rate': \"\n",
      " \"0.5121951219512195}, {'num_entries': 206, 'column_name': 'almondnuts', \"\n",
      " \"'true_positive': 1, 'false_positive': 0, 'false_negative': 82, \"\n",
      " \"'true_negative': 123, 'precision': 1.0, 'recall': 0.012048192771084338, \"\n",
      " \"'f1_score': 0.02380952380952381, 'accuracy': 0.6019417475728155, \"\n",
      " \"'false_positive_rate': 0.0, 'false_negative_rate': 0.9879518072289156}, \"\n",
      " \"{'num_entries': 206, 'column_name': 'brazil_nuts', 'true_positive': 0, \"\n",
      " \"'false_positive': 0, 'false_negative': 8, 'true_negative': 198, 'precision': \"\n",
      " \"0.0, 'recall': 0.0, 'f1_score': 0.0, 'accuracy': 0.9611650485436893, \"\n",
      " \"'false_positive_rate': 0.0, 'false_negative_rate': 1.0}, {'num_entries': \"\n",
      " \"206, 'column_name': 'macadamia_nuts', 'true_positive': 0, 'false_positive': \"\n",
      " \"0, 'false_negative': 6, 'true_negative': 200, 'precision': 0.0, 'recall': \"\n",
      " \"0.0, 'f1_score': 0.0, 'accuracy': 0.970873786407767, 'false_positive_rate': \"\n",
      " \"0.0, 'false_negative_rate': 1.0}, {'num_entries': 206, 'column_name': \"\n",
      " \"'hazelnut', 'true_positive': 6, 'false_positive': 1, 'false_negative': 15, \"\n",
      " \"'true_negative': 184, 'precision': 0.8571428571428571, 'recall': \"\n",
      " \"0.2857142857142857, 'f1_score': 0.42857142857142855, 'accuracy': \"\n",
      " \"0.9223300970873787, 'false_positive_rate': 0.005405405405405406, \"\n",
      " \"'false_negative_rate': 0.7142857142857143}, {'num_entries': 206, \"\n",
      " \"'column_name': 'pistachio', 'true_positive': 0, 'false_positive': 0, \"\n",
      " \"'false_negative': 8, 'true_negative': 198, 'precision': 0.0, 'recall': 0.0, \"\n",
      " \"'f1_score': 0.0, 'accuracy': 0.9611650485436893, 'false_positive_rate': 0.0, \"\n",
      " \"'false_negative_rate': 1.0}, {'num_entries': 206, 'column_name': 'walnut', \"\n",
      " \"'true_positive': 0, 'false_positive': 0, 'false_negative': 12, \"\n",
      " \"'true_negative': 194, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, \"\n",
      " \"'accuracy': 0.941747572815534, 'false_positive_rate': 0.0, \"\n",
      " \"'false_negative_rate': 1.0}, {'num_entries': 206, 'column_name': 'cashew', \"\n",
      " \"'true_positive': 0, 'false_positive': 0, 'false_negative': 22, \"\n",
      " \"'true_negative': 184, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, \"\n",
      " \"'accuracy': 0.8932038834951457, 'false_positive_rate': 0.0, \"\n",
      " \"'false_negative_rate': 1.0}, {'num_entries': 206, 'column_name': 'celery', \"\n",
      " \"'true_positive': 5, 'false_positive': 3, 'false_negative': 9, \"\n",
      " \"'true_negative': 189, 'precision': 0.625, 'recall': 0.35714285714285715, \"\n",
      " \"'f1_score': 0.45454545454545453, 'accuracy': 0.941747572815534, \"\n",
      " \"'false_positive_rate': 0.015625, 'false_negative_rate': 0.6428571428571429}, \"\n",
      " \"{'num_entries': 206, 'column_name': 'crustaceans', 'true_positive': 0, \"\n",
      " \"'false_positive': 2, 'false_negative': 0, 'true_negative': 204, 'precision': \"\n",
      " \"0.0, 'recall': 0.0, 'f1_score': 0.0, 'accuracy': 0.9902912621359223, \"\n",
      " \"'false_positive_rate': 0.009708737864077669, 'false_negative_rate': 0.0}, \"\n",
      " \"{'num_entries': 206, 'column_name': 'eggs', 'true_positive': 4, \"\n",
      " \"'false_positive': 1, 'false_negative': 1, 'true_negative': 200, 'precision': \"\n",
      " \"0.8, 'recall': 0.8, 'f1_score': 0.8000000000000002, 'accuracy': \"\n",
      " \"0.9902912621359223, 'false_positive_rate': 0.004975124378109453, \"\n",
      " \"'false_negative_rate': 0.2}, {'num_entries': 206, 'column_name': 'fish', \"\n",
      " \"'true_positive': 0, 'false_positive': 2, 'false_negative': 0, \"\n",
      " \"'true_negative': 204, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, \"\n",
      " \"'accuracy': 0.9902912621359223, 'false_positive_rate': 0.009708737864077669, \"\n",
      " \"'false_negative_rate': 0.0}, {'num_entries': 206, 'column_name': 'gluten', \"\n",
      " \"'true_positive': 18, 'false_positive': 4, 'false_negative': 10, \"\n",
      " \"'true_negative': 174, 'precision': 0.8181818181818182, 'recall': \"\n",
      " \"0.6428571428571429, 'f1_score': 0.7200000000000001, 'accuracy': \"\n",
      " \"0.9320388349514563, 'false_positive_rate': 0.02247191011235955, \"\n",
      " \"'false_negative_rate': 0.35714285714285715}, {'num_entries': 206, \"\n",
      " \"'column_name': 'lupin', 'true_positive': 1, 'false_positive': 2, \"\n",
      " \"'false_negative': 4, 'true_negative': 199, 'precision': 0.3333333333333333, \"\n",
      " \"'recall': 0.2, 'f1_score': 0.25, 'accuracy': 0.970873786407767, \"\n",
      " \"'false_positive_rate': 0.009950248756218905, 'false_negative_rate': 0.8}, \"\n",
      " \"{'num_entries': 206, 'column_name': 'milk', 'true_positive': 19, \"\n",
      " \"'false_positive': 3, 'false_negative': 9, 'true_negative': 175, 'precision': \"\n",
      " \"0.8636363636363636, 'recall': 0.6785714285714286, 'f1_score': 0.76, \"\n",
      " \"'accuracy': 0.941747572815534, 'false_positive_rate': 0.016853932584269662, \"\n",
      " \"'false_negative_rate': 0.32142857142857145}, {'num_entries': 206, \"\n",
      " \"'column_name': 'molluscs', 'true_positive': 0, 'false_positive': 0, \"\n",
      " \"'false_negative': 0, 'true_negative': 206, 'precision': 0.0, 'recall': 0.0, \"\n",
      " \"'f1_score': 0.0, 'accuracy': 1.0, 'false_positive_rate': 0.0, \"\n",
      " \"'false_negative_rate': 0.0}, {'num_entries': 206, 'column_name': 'mustard', \"\n",
      " \"'true_positive': 2, 'false_positive': 3, 'false_negative': 9, \"\n",
      " \"'true_negative': 192, 'precision': 0.4, 'recall': 0.18181818181818182, \"\n",
      " \"'f1_score': 0.25000000000000006, 'accuracy': 0.941747572815534, \"\n",
      " \"'false_positive_rate': 0.015384615384615385, 'false_negative_rate': \"\n",
      " \"0.8181818181818182}, {'num_entries': 206, 'column_name': 'peanut', \"\n",
      " \"'true_positive': 5, 'false_positive': 8, 'false_negative': 10, \"\n",
      " \"'true_negative': 183, 'precision': 0.38461538461538464, 'recall': \"\n",
      " \"0.3333333333333333, 'f1_score': 0.3571428571428571, 'accuracy': \"\n",
      " \"0.912621359223301, 'false_positive_rate': 0.041884816753926704, \"\n",
      " \"'false_negative_rate': 0.6666666666666666}, {'num_entries': 206, \"\n",
      " \"'column_name': 'sesame', 'true_positive': 12, 'false_positive': 6, \"\n",
      " \"'false_negative': 14, 'true_negative': 174, 'precision': 0.6666666666666666, \"\n",
      " \"'recall': 0.46153846153846156, 'f1_score': 0.5454545454545455, 'accuracy': \"\n",
      " \"0.9029126213592233, 'false_positive_rate': 0.03333333333333333, \"\n",
      " \"'false_negative_rate': 0.5384615384615384}, {'num_entries': 206, \"\n",
      " \"'column_name': 'soy', 'true_positive': 12, 'false_positive': 9, \"\n",
      " \"'false_negative': 13, 'true_negative': 172, 'precision': 0.5714285714285714, \"\n",
      " \"'recall': 0.48, 'f1_score': 0.5217391304347826, 'accuracy': \"\n",
      " \"0.8932038834951457, 'false_positive_rate': 0.049723756906077346, \"\n",
      " \"'false_negative_rate': 0.52}, {'num_entries': 206, 'column_name': 'sulfite', \"\n",
      " \"'true_positive': 0, 'false_positive': 0, 'false_negative': 0, \"\n",
      " \"'true_negative': 206, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, \"\n",
      " \"'accuracy': 1.0, 'false_positive_rate': 0.0, 'false_negative_rate': 0.0}], \"\n",
      " \"'time_taken': 219.03006076812744}\")\n"
     ]
    }
   ],
   "source": [
    "# Evaluate results\n",
    "\n",
    "jupyter_helper_functions.standardize_and_evaluate(\n",
    "    gold_standard=gold_standard,\n",
    "    merged_df=merged_df,\n",
    "    corrupt_dataset=corrupt_dataset,\n",
    "    primary_key=primary_key,\n",
    "    time_delta=time_taken,\n",
    "    results_dir=f\"../analysis/results/allergen/\",\n",
    "    file_name=file_name,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ead7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
